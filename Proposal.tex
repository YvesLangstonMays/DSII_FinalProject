\documentclass{report}

% Encoding and Packages
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[margin=1in,top=0.5in]{geometry}
\usepackage[x11names,table]{xcolor}
\usepackage{fancyhdr}
\usepackage{tcolorbox}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{pdflscape}
\usepackage{caption}
\usepackage{float}
\usepackage{etex}
\usepackage{luatex85}
\usepackage{etoc}
\usepackage{expl3}
\usepackage{amsmath}  % <-- Add this line

% Header height
\setlength{\headheight}{3cm}

% Section numbering
\renewcommand{\thesection}{\arabic{section}.}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}.}

% Adjust section levels
\makeatletter
\renewcommand\section{\@startsection{section}{1}{\z@}%
  {-3.5ex \@plus -1ex \@minus -.2ex}%
  {2.3ex \@plus.2ex}%
  {\normalfont\Large\bfseries}}
\makeatother

% Table of Contents depth
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}

% Fancy Header and Footer Setup
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{\includegraphics[width=0.8\textwidth]{UHLogo_Long.png}}
\fancyfoot[C]{\thepage}
\fancyfoot[L]{Yves-Langston Mays 2 December 2024}
\fancyfoot[R]{\today}

% Etoc settings
\etocsetlevel{section}{0}
\etocsetnexttocdepth{3}

% Increase TeX's main memory size
\directlua{
  pdf.setminorversion(7)
  pdf.setobjcompresslevel(0)
  pdf.setcompresslevel(0)
}

% Increase LaTeX counters
\maxdeadcycles=1000
\extrafloats{1000}

% Increase TeX parameters
\ExplSyntaxOn
\dim_new:N \g_fpi_maxheight_dim
\dim_gset:Nn \g_fpi_maxheight_dim {16383pt}
\ExplSyntaxOff

% Define tightlist command
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Hyperref settings (should be last)
\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    linkcolor=black,
    filecolor=black,
    urlcolor=black,
    pdfborder={0 0 0},
}

\begin{document}

% Title Page
\begin{titlepage}
    \centering
    \vspace*{5cm}
    
    {\Huge \textbf{Predicting Transcription Factor Binding Sites Using a CNN}} \\[1.5em]
    
    {\Large P-value > 0.5} \\[1.5em]
    
    \begin{center}
        {\large
        Yves-Langston Mays \\
        Wyatt Lamberth \\
        Michael Carreno \\
        Pierre Ingram \\
        Alexander Rosales \\
        Victoria Vu
        }
    \end{center}
    
    \vfill
    \includegraphics[width=0.5\textwidth]{UHLogo_Long.png}
    \vspace{0.8cm}
\end{titlepage}


% Table of Contents
\begingroup
\let\clearpage\relax
\tableofcontents
\endgroup
\relax
\relax

% Body Content Placeholder
\newpage

\section{Project Timeline*}\label{project-timeline}

\begin{longtable}[]{@{}clc@{}}
\toprule\noalign{}
Milestone & Due Date & Task \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Proposal Submission & March 21, 2025 & Submit Proposal \\
Progress Report & April 11, 2025 & Process Dataset and train CNN \\
Final Report & April 28, 2025 & Evaluate Moel, Handle Errors \\
\end{longtable}

\subsection{Objective}\label{objective}

The goal of this project is to predict transcription factor binding
sites in eukaryotic DNA using a 1 dimensional CNN. Our goal is to
determine whether a 200 bp DNA sequence contains a binding site for a
single transcription factor.

\newpage

\section{Background}\label{background}

Transcription factors are proteins that regulate gene expression by
binding to specific DNA motifs in promoter regions. Accurately
predicting these binding sites can be useful for:

Synthetic biology -- Designing custom promoters for gene circuits

Gene therapy -- Targeted activation or repression of genes

Functional genomics -- Understanding regulatory networks in eukaryotic
cells

\section{Task Definition}\label{task-definition}

Input: A 200 bp DNA sequence represented using one hot encoding

Output: Binary classification (1 = TF binding site, 0 = no TF binding
site)

Approach: Train a CNN model to learn DNA sequence motifs associated with
TF binding

\subsection{Example Inputs}\label{example-inputs}

\begin{longtable}[]{@{}lc@{}}
\toprule\noalign{}
DNA Sequence & Label \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ATGCCGTTAGCGTAC\ldots{} & 1 (Binding Site) \\
CGTATAGGCCGCTAA\ldots{} & 0 (No Binding Site) \\
\end{longtable}

\subsection{Example Outputs}\label{example-outputs}

\begin{longtable}[]{@{}lcc@{}}
\toprule\noalign{}
DNA Sequence & Probability & Label \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ATGCCGTTAGCGTAC\ldots{} & 0.96 & 1 (Binding Site) \\
CGTATAGGCCGCTAA\ldots{} & 0.18 & 0 (No Binding Site) \\
\end{longtable}

\newpage

\section{Data Source}\label{data-source}

JASPAR Database (jaspar.genereg.net) -- Provides validated TF binding
sites for transcription factors

Synthetic Negative Samples -- Generated by shuffling non-binding
sequences from background genomic DNA to balance the dataset. This
prevents the model from becoming biased towards positive samples and
reduces overfitting, thus decreasing false positives.

\section{Preprocessing Steps}\label{preprocessing-steps}

One hot encode DNA sequences

Standardize all sequences to 200 bp

Introduce small mutations to sequences through swapping or deleting
bases to simulate natural variation to provide more natural data.

Improve model generalization by applying techniques such as dropout,
normalization, and data shuffling to improve model generalization.

Could potentially utilize positional information to account for
perferencial positioning of binding sites and use secondary structure
prediction to identify secondary structure features that may influence
transcription factor binding.

Data could benefit from utilizing reverse complement sequences to create
better generalization through learning binding sites from both strands
of DNA.

\section{Evaluating Metric}\label{evaluating-metric}

\textbf{Accuracy} -- Overall model performance\\
- \textbf{AUC-ROC (Area Under the Curve - Receiver Operating
Characteristic)}\\
- Assesses the model's ability to distinguish between binding
vs.~non-binding sites\\
- ROC Curve plots TPR vs.~FPR across different thresholds\\
- AUC Score closer to 1 indicates better classification performance\\
- \textbf{Baseline Comparison} -- The CNN will be compared against a
random classifier (50\% accuracy baseline) and a logistic regression
baseline.

\section{Model Selection}\label{model-selection}

1D Convolutional Neural Networks (CNNs) are particularly effective for
identifying sequence motifs in DNA because they can capture spatial
hierarchies in sequential data. CNNs efficiently detect local patterns
(such as binding motifs) through convolutional layers, making them
suitable for biological sequence classification tasks where positional
information is critical.

\section{CNN Design}\label{cnn-design}

Input Layer: One hot encoded DNA sequence

Conv Layer 1: 16 filters, kernel size = 8, ReLU activation

Conv Layer 2: 32 filters, kernel size = 4, ReLU activation

Pooling Layers: Max-pooling layers (pool size = 2) after each
convolutional layer to reduce dimensionality and control overfitting.
Regularization Techniques: Dropout (rate = 0.5) applied after the Dense
Layer to prevent overfitting. Optimization Algorithm: Adam optimizer due
to its efficiency and adaptive learning rate capabilities. Learning
Rate: Initial learning rate of 0.001, with adaptive adjustments using
learning rate scheduling if necessary.

Flatten Layer

Dense Layer: Fully connected layer with 32 neurons

Output Layer: Sigmoid activation for binary classification

\section{Small Mutations to Improve Model
Generalization}\label{small-mutations-to-improve-model-generalization}

Small mutations, such as random substitutions (e.g., A â†’ G) and
insertion/deletion of single nucleotides at random positions, introduce
realistic variability. This improves the CNN's generalization ability,
allowing it to perform better on unseen biological sequences.

\section{Potential Areas for Model Improvement (Exploration
Phase)}\label{potential-areas-for-model-improvement-exploration-phase}

As part of early experimentation and optional exploration by team
members, a few potential improvements have been considered for future
iterations of the model. These ideas are \textbf{not finalized}, but may
help inform model tuning discussions later in the project.

\begin{itemize}
\tightlist
\item
  \textbf{Global MaxPooling Layers}: May help the CNN detect motifs
  regardless of their position in the sequence.
\item
  \textbf{Reduced Regularization}: Lower dropout or L2 penalty could
  preserve meaningful motif representations that are otherwise
  suppressed.
\item
  \textbf{Fixed-Position Motif Embedding}: Embedding motifs at a known
  sequence position during dataset generation may improve learnability.
\item
  \textbf{Filter Visualization}: Extracting convolutional filters to
  interpret what patterns the CNN is learning.
\item
  \textbf{Logistic Regression Baseline}: Comparing CNN performance to a
  baseline logistic regression model using k-mer frequency or TF-IDF
  features.
\item
  \textbf{Class Weighting Adjustments}: Exploring how weighting the loss
  function by class frequency might reduce class prediction bias.
\end{itemize}

These improvements are \textbf{currently exploratory} and can be
incorporated during model tuning stages if the group agrees they are
beneficial.

\end{document}
